% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/screen_analyzer.R
\name{screen_analyzer}
\alias{screen_analyzer}
\title{Analyzing screening performance between the human and AI screening.}
\usage{
screen_analyzer(x, human_decision = human_code)
}
\arguments{
\item{x}{Either an object of class \code{'chatgpt'} or a data set of class \code{'chatgpt_tbl'}}

\item{human_decision}{Indicate the variable in the data that contains the human_decision.
This variable must be numeric containing 1 (for included references) and 0 (for excluded references) only.}
}
\value{
An \code{tibble} with performance measures
}
\description{
\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}}\if{html}{\out{<br>}}
\if{html}{\out{<br>}}
When both the human and AI title and abstract screening has been done, this function
allows you to calculate performance measures of the screening, including the overall
accuracy, specificity and sensitivity of the screening, as well as
interrater reliability kappa statistics.
}
\examples{
\dontrun{
x <- AIscreenR:::result_object
screen_analyzer(x)
}
}
