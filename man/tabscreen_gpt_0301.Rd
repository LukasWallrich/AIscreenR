% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tabscreen_chatgpt.R
\name{tabscreen_gpt_0301}
\alias{tabscreen_gpt_0301}
\title{Title and abstract screening with ChatGPT (0301 models)}
\usage{
tabscreen_gpt_0301(
  data,
  prompt,
  studyid,
  title,
  abstract,
  ...,
  arrange_var = studyid,
  time_info = TRUE,
  token_info = TRUE,
  model = "gpt-3.5-turbo-0301",
  role = "user",
  api_key = get_api_key(),
  max_tries = 2,
  max_seconds = NULL,
  is_transient = gpt_is_transient,
  backoff = NULL,
  after = NULL,
  rpm = 3500,
  reps = 1,
  seed = NULL
)
}
\arguments{
\item{data}{Data with title and abstracts}

\item{prompt}{Prompt(s) to paste before title and abstract}

\item{studyid}{ID indication unique ID of study. Is missing, this is generated
automatically.}

\item{title}{Name of variable with containing title information}

\item{abstract}{Name of variable with containing abstract information}

\item{...}{Further argument to pass to the request body.
See \url{https://platform.openai.com/docs/api-reference/chat/create}.}

\item{arrange_var}{Function indicating the variables determing the arrangement of the data. Default is \code{studyid}.}

\item{time_info}{Logical indicating whether the run time of each
request/question should be included in the data. Default = \code{TRUE}.}

\item{token_info}{Logical indicating whether the total number of tokens
per request should be included in the output data. Default = \code{TRUE}.}

\item{model}{Character string with the name of the completion model.
Default = \code{"gpt-3.5-turbo-0301"}. Find available model at
\url{https://platform.openai.com/docs/models/model-endpoint-compatibility}.}

\item{role}{Character string indicate the role of the user. Default is \code{"user"}.}

\item{api_key}{Numerical value with your personal API key. Find at
\url{https://platform.openai.com/account/api-keys}. Use
\code{\link[=secret_make_key]{secret_make_key()}}, \code{\link[=secret_encrypt]{secret_encrypt()}}, and
\code{\link[=secret_decrypt]{secret_decrypt()}} to scramble and decrypt the api key and
use \code{\link[=set_api_key]{set_api_key()}} to securely automate the use of the
api key by setting the api key as a locale environment variable.}

\item{max_tries, max_seconds}{'Cap the maximum number of attempts with
\code{max_tries} or the total elapsed time from the first request with
\code{max_seconds}. If neither option is supplied (the default), \code{\link[=req_perform]{req_perform()}}
will not retry' (Wickham, 2023).}

\item{is_transient}{'A predicate function that takes a single argument
(the response) and returns \code{TRUE} or \code{FALSE} specifying whether or not
the response represents a transient error' (Wickham, 2023).}

\item{backoff}{'A function that takes a single argument (the number of failed
attempts so far) and returns the number of seconds to wait' (Wickham, 2023).}

\item{after}{'A function that takes a single argument (the response) and
returns either a number of seconds to wait or \code{NULL}, which indicates
that a precise wait time is not available that the \code{backoff} strategy
should be used instead' (Wickham, 2023).}

\item{rpm}{Numerical value indicating the number of requests per minute (rpm)
available for the specified api key. Find more information at
\url{https://platform.openai.com/docs/guides/rate-limits/what-are-the-rate-limits-for-our-api}.
Alternatively, use \code{\link[=rate_limits_per_minute]{rate_limits_per_minute()}}.}

\item{reps}{Numerical value indicating the number of times the same
question should be sent to ChatGPT. This can be useful to test consistency
between answers. Default is \code{1}.}

\item{seed}{Numerical value for a seed to ensure that proper,
parallel-safe random numbers are produced.}
}
\value{
A \code{tibble} with answer and run_time if \code{time_info = TRUE}.
}
\description{
This function supports the conduct of title and abstract screening with ChatGPT in R.
The function allow to run title and abstract screening across multiple prompts and with
repeated questions to check for consistency across answers
}
\examples{
\dontrun{
library(future)

# Find your api key at https://platform.openai.com/account/api-keys
set_api_key()

data <- load("data.RData")
prompts <- paste("Prompt", 1:3)

plan(multisession, workers = 7)

system.time(
 test_dat <-
  tabscreen_chatgpt(
    data = data,
    prompt = prompts,
    studyid = studyid,
    title = Title,
    abstract = Abstract
 )
)
}
}
\references{
Wickham H (2023).
\emph{httr2: Perform HTTP Requests and Process the Responses}.
https://httr2.r-lib.org, https://github.com/r-lib/httr2.
}
